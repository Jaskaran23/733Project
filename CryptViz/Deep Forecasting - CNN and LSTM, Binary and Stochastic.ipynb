{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting the Cryptocurrency Ecosystem with Deep Learning\n",
    "In this notebook we will collect price history data for the top 100 coins by marketcap. We will chunk data into 2D tensors of 90x5 where 90 is number of days of input, and 5 is  the number of feature points per coin per day. Feature points are: ['Open', 'High', 'Low', 'Close', 'DayOfYear'].\n",
    "\n",
    "From this time series data, our model will learn to predict how prices will change 1, 10, 30, and 90 days in the future. Our experiments include both an LSTM and a CNN implementation, both of which take the same data as input. \n",
    "\n",
    "We will do three types of price forecasting:\n",
    "1. Binary Prediction: \n",
    "For each coin, predict if the price of that coin will be higher or lower in n days.\n",
    "2. Linear Prediction:\n",
    "Predict the actual price change of a coin at a future date.\n",
    "3. Stochastic Forecasting: \n",
    "Produce a stochastic evaluation over all coins. That is, produce a vector of length equal to number of coins, whos elements are non-zero and sum to one. Each element of the vector is a scalar evaluation of a coin. This vector can be thought of as a confidence distribution over the coins, where the higher the evaluation, the higher the confidence of gain in price. This vector can also be used to simulate an investment portfolio, as a portfolio can be seen as a stochastiv vector of assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import tqdm\n",
    "\n",
    "DAYS_BLK  = 90 # Number of input days for learning\n",
    "TARGETS   = [1, 10, 30, 90] # Number of days to predict in the future\n",
    "TEST_DAYS = 30 # Number of most recent days to withold from the training set for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Acquisition and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_samples(coins, DAYS_BLK, TARGETS):\n",
    "    # Compile a list of training examples, accompanied by target values for future prices\n",
    "    train_samples = []\n",
    "    for coin in tqdm.tqdm(coins):\n",
    "        # Get all available price history for a given coin\n",
    "        coin_data = coin.read_history()\n",
    "\n",
    "        # Drop unneccessary columns\n",
    "        coin_data = coin_data.drop(['Volume', 'Market Cap', 'Unnamed: 0'], 1) \n",
    "\n",
    "        # Reverse date ordering so we predict the future instead of the past\n",
    "        coin_data['Date'] = pd.to_datetime(coin_data['Date'])\n",
    "        coin_data = coin_data.sort_values(['Date']) \n",
    "\n",
    "        # Convert Date to Day of Year(DOY)\n",
    "        coin_data['DOY'] = coin_data['Date'].apply(lambda x: x.dayofyear)\n",
    "        coin_data = coin_data.drop(['Date'], 1)\n",
    "\n",
    "        # Chunk coin history into input/target train pairs\n",
    "        for t in range(len(coin_data) - DAYS_BLK - TARGETS[-1] - TEST_DAYS):\n",
    "\n",
    "            # X is a 90 day chunk of shape: (90, 5)\n",
    "            X = coin_data.iloc[t:t+DAYS_BLK].copy()\n",
    "            # y is a list of future prices [1, 10, 30, 90] days after X\n",
    "            y = [coin_data.iloc[t+DAYS_BLK+n]['Close'] for n in TARGETS]\n",
    "\n",
    "            # Normalize prices relative to the final input close price\n",
    "            price_cols = ['Open', 'High', 'Low', 'Close']\n",
    "            current_price = X.values[-1][3]\n",
    "            for col in price_cols:\n",
    "                X[col] = X[col] / current_price\n",
    "\n",
    "            # Normalize future prices by current price\n",
    "            y = [future_price / current_price for future_price in y]\n",
    "\n",
    "            # Normalize DOY column\n",
    "            X['DOY'] = X['DOY'] / 365\n",
    "\n",
    "            # Sample is ready\n",
    "            train_samples.append((X.values, y))\n",
    "    return train_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of coin objects for the top 100 coins from coinmarketcap.com\n",
    "from Scrapers.Coinmarketcap.coinmarketcap import CoinMarketcap\n",
    "cmk = CoinMarketcap()\n",
    "coins = cmk.coins()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:03<00:00,  1.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# Cache samples because compiling them is timely\n",
    "RECOMPILE_SAMPLES = True\n",
    "if RECOMPILE_SAMPLES:\n",
    "    samples = compile_samples(coins, DAYS_BLK, TARGETS)\n",
    "    pickle.dump(samples, open( \"dataset.pickle\", \"wb\" ) )\n",
    "else:\n",
    "    try:\n",
    "        print(\"Checking Cache...\")\n",
    "        samples = pickle.load(open('dataset.pickle','rb'))\n",
    "        print(\"Cached samples loaded!\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Cached samples not found. Fetching data and compiling samples...\")\n",
    "        samples = compile_samples(coins, DAYS_BLK, TARGETS)\n",
    "        print(\"Caching samples...\")\n",
    "        pickle.dump(samples, open( \"dataset.pickle\", \"wb\" ) )\n",
    "        print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34926"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dense, Flatten\n",
    "\n",
    "# Assert input shape\n",
    "N = 90 # Number of Days\n",
    "F = 5  # Number of Features: ['Open', 'High', 'Low', 'Close', 'DayOfYear']\n",
    "assert((N, F) == samples[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(forecast='binary'):\n",
    "    # Define our Temporal Convolutional Model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=4, kernel_size=3, activation='selu', input_shape=[N,F]))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=4, kernel_size=3, activation='selu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=16, kernel_size=21, activation='selu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid')) # 'linear' for price prediction, 'softmax' for stochastic forecasting\n",
    "    \n",
    "    # Compile our Model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Binary Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many days into the future would you like to predict? Options: [1,10,30,90]\n",
    "n_days = 30\n",
    "target_index = TARGETS.index(n_days)\n",
    "\n",
    "# Split samples into inputs and targets\n",
    "X,y = zip(*samples)\n",
    "\n",
    "# target[0] is the price 1 day after input\n",
    "y = [target[0] for target in y]\n",
    "\n",
    "# convert target to boolean. 0 means price went down, 1 means price went up\n",
    "y = [int(target>1) for target in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27940 samples, validate on 6986 samples\n",
      "Epoch 1/10\n",
      "27940/27940 [==============================] - 4s 143us/step - loss: 0.6917 - acc: 0.5335 - mean_absolute_error: 0.4950 - val_loss: 0.6922 - val_acc: 0.5289 - val_mean_absolute_error: 0.4974\n",
      "Epoch 2/10\n",
      "27940/27940 [==============================] - 3s 103us/step - loss: 0.6884 - acc: 0.5413 - mean_absolute_error: 0.4942 - val_loss: 0.6908 - val_acc: 0.5302 - val_mean_absolute_error: 0.4953\n",
      "Epoch 3/10\n",
      "27940/27940 [==============================] - 3s 105us/step - loss: 0.6866 - acc: 0.5496 - mean_absolute_error: 0.4928 - val_loss: 0.6910 - val_acc: 0.5401 - val_mean_absolute_error: 0.4930\n",
      "Epoch 4/10\n",
      "27940/27940 [==============================] - 3s 104us/step - loss: 0.6853 - acc: 0.5561 - mean_absolute_error: 0.4915 - val_loss: 0.6883 - val_acc: 0.5457 - val_mean_absolute_error: 0.4940\n",
      "Epoch 5/10\n",
      "27940/27940 [==============================] - 3s 107us/step - loss: 0.6839 - acc: 0.5590 - mean_absolute_error: 0.4905 - val_loss: 0.6923 - val_acc: 0.5359 - val_mean_absolute_error: 0.4936\n",
      "Epoch 6/10\n",
      "27940/27940 [==============================] - 3s 105us/step - loss: 0.6824 - acc: 0.5621 - mean_absolute_error: 0.4892 - val_loss: 0.6886 - val_acc: 0.5470 - val_mean_absolute_error: 0.4917\n",
      "Epoch 7/10\n",
      "27940/27940 [==============================] - 3s 106us/step - loss: 0.6815 - acc: 0.5654 - mean_absolute_error: 0.4882 - val_loss: 0.6873 - val_acc: 0.5544 - val_mean_absolute_error: 0.4899\n",
      "Epoch 8/10\n",
      "27940/27940 [==============================] - 3s 111us/step - loss: 0.6808 - acc: 0.5646 - mean_absolute_error: 0.4875 - val_loss: 0.6878 - val_acc: 0.5497 - val_mean_absolute_error: 0.4898\n",
      "Epoch 9/10\n",
      "27940/27940 [==============================] - 3s 108us/step - loss: 0.6800 - acc: 0.5699 - mean_absolute_error: 0.4868 - val_loss: 0.6860 - val_acc: 0.5545 - val_mean_absolute_error: 0.4898\n",
      "Epoch 10/10\n",
      "27940/27940 [==============================] - 3s 107us/step - loss: 0.6793 - acc: 0.5693 - mean_absolute_error: 0.4860 - val_loss: 0.6847 - val_acc: 0.5537 - val_mean_absolute_error: 0.4895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f655a616898>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN()\n",
    "model.fit(np.array(X), np.array(y), epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mae']"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test Set Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convulutional Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long Short Term Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Stochastic Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test Set Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "733Project",
   "language": "python",
   "name": "733project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
